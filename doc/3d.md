# 3D Data Structure
This document describes data structure used for rendering 3D context.

# OpenGL objects

## Primitives
Because the game works on WebGL, the structure must implement OpenGL
primitives, which uses TypedArray. Some benchmarks show that creating new
TypedArray object is slower than creating its Object / Array equivalent.

So the data structure should cache TypedArray objects and use it as a mutable
object if possible. Base game engine (State manager) already uses TypedArray
for storing position data, so this won't be hard.

[glMatrix](http://glmatrix.net/) will handle all the troublesome vector and
matrix related operations. (It's completely useless to reimplement things like
that, although I'm kinda trying to 'reinvent the wheel' (But I'm doing this
to learn stuff).)

All primitives will be handled with TypedArray, because WebGL standard requires
it. (and it'd be faster)

However, we need to upload TypedArray objects to the GPU in order to render it
on the screen. Uploading such objects requires creating a buffer object.

## VBO
VBO (Vertex Buffer Object) is used as a source for drawing vertex data,
residing in the GPU. The program can't access VBO directly - it needs to use
OpenGL command to upload buffer data.

VBO (usually) specifies the data to draw one mesh - each vertices' position,
color, normal, tangent, texture position are stored in the VBO, like a block
in the memory. Then we specify the position of each data in VBO.

Since VBO object is just a pointer for the memory in GPU, it's important to
delete buffer object after use.

It's a good idea to share data between same geometry (but have different
texture, color, material, etc). We should maintain the geometry VBO by
wrapping it with Geometry class.

But sometimes we may want to render the wireframe of the object. Sadly
OpenGL ES (and WebGL) does not support glPolygonMode, so we have to create
triangle lines manually. Luckily we don't have to re-upload whole VBO - we
only have to re-upload index buffers. Should we make GeometryConverter class
which converts triangles to lines? Or alternatively, should we support
that in the mesh?

### Instancing
However, we also have to implement 'instancing', which enables to draw multiple
same meshs (sharing same geometry and material) faster than calling draw calls
multiple times. If we're using it, we need to call different draw call which
is different from normal draw call, so Geometry class shouldn't call the draw
call, or it should handle instancing draw call.

Instancing also uses VBO, and we can make separate class for managing it.
However since instancing requires every object to share same mesh, instancing
container object should handle these in order:

1. Bind geometry and material object
2. Collect transform information from children
3. Upload it to the GPU (if it has invalidated)
4. Call instanced draw call
5. Unbind geometry, material, instance buffer

However we've to decide whether if we should contain the geometry and material
object in the instancing container object and ignore children's mesh data,
or if we should use the first children's mesh data.

We also should make fallback which use individual draw calls for devices
that don't support `ANGLE_instanced_arrays` extension.

## VAO
Even if we use VBO, We still have to bind/unbind buffers and reallocate
the attribute pointers every time we draw an object! That's pretty awkward
so OpenGL also have a VAO, which contains the VBO pointers, attribute pointers
information, etc...

If we use VAO, we can just bind single VAO object and call draw call right
after that - much faster. We still have to bind uniform objects, though.

VAO requires `OES_vertex_array_object` extension. (So we need fallback as well.)

## UBO
In OpenGL ES 3.1, Uniform buffer object is supported too, but WebGL doesn't
support it. (WebGL 2 supports it though)

## Texture
Texture is an image used in GPU (of course). We can simply create OpenGL
texture by calling `createTexture`, however we have to upload image data after
that, just like any other OpenGL objects like VBO, VAO, etc.

Image data can be provided using DOM API objects, such as Image element,
Canvas element, Video element, or TypedArray.

Since JavaScript is asynchronous, we must wait until the image is loaded
if the image hasn't loaded yet. We'll need a class for representing and
managing texture and image data.

Using a texture in a shader is kinda different than other OpenGL objects.

First, we have to activate a texture unit using `activeTexture`.
Texture unit can contain one texture, and there are at least 8 texture units
in the GPU. (This means it is possible to use at least 8 textures at
the same time in a single draw call)

Next, we bind the texture to texture unit using `bindTexture`. It works just
like binding VBO.

Next, we set the uniform to the texture unit ID, then OpenGL will bind that
to opaque sampler object in shader.

# OOP Representation
